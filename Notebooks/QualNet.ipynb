{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import cmath\n",
    "import scipy\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import layers,regularizers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, concatenate\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import imageio.v3 as iio\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5dff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = \"C:/Users/yrq64132/OneDrive - Science and Technology Facilities Council/Documents/MATLAB/Petros/DeepLearning/ImQual_Dataset_nonroot2\"\n",
    "images = os.listdir(data_loc + \"/Train/Images\")\n",
    "labels = os.listdir(data_loc + \"/Train/Labels\")\n",
    "\n",
    "\n",
    "X_train_orig = list()\n",
    "Y_train_orig = list()\n",
    "n_train_images = np.shape(images)[0]\n",
    "for i in tqdm(range(np.shape(images)[0])):\n",
    "    X_train_orig.append(iio.imread(data_loc + \"/Train/Images/\" + images[i]))\n",
    "    Y_train_orig.append(pd.read_csv(data_loc + \"/Train/Labels/\" + labels[i], header = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b671f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = np.shape(X_train_orig)[1]\n",
    "n_coeffs = np.shape(Y_train_orig)[1]\n",
    "image_shape = (resolution,resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df92151",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train_orig,[n_train_images, resolution, resolution, 1]).astype(int)\n",
    "Y_train = np.reshape(Y_train_orig,[n_train_images, n_coeffs]).astype(np.single)\n",
    "\n",
    "images_train_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "labels_train_dataset = tf.data.Dataset.from_tensor_slices(Y_train)\n",
    "train_dataset = tf.data.Dataset.zip((images_train_dataset, labels_train_dataset))\n",
    "train_dataset = train_dataset.batch(64, drop_remainder = False)\n",
    "train_dataset = train_dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(data_loc + \"/Test/Images\")\n",
    "labels = os.listdir(data_loc + \"/Test/Labels\")\n",
    "\n",
    "\n",
    "X_test_orig = list()\n",
    "Y_test_orig = list()\n",
    "n_test_images = np.shape(images)[0]\n",
    "for i in tqdm(range(np.shape(images)[0])):\n",
    "    X_test_orig.append(iio.imread(data_loc + \"/Test/Images/\" + images[i]))\n",
    "    Y_test_orig.append(pd.read_csv(data_loc + \"/Test/Labels/\" + labels[i], header = None))\n",
    "\n",
    "X_test = np.reshape(X_test_orig,[n_test_images, resolution, resolution, 1]).astype(int)\n",
    "Y_test = np.reshape(Y_test_orig,[n_test_images, n_coeffs]).astype(np.single)\n",
    "\n",
    "images_test_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "labels_test_dataset = tf.data.Dataset.from_tensor_slices(Y_test)\n",
    "test_dataset = tf.data.Dataset.zip((images_test_dataset, labels_test_dataset))\n",
    "test_dataset = test_dataset.batch(64, drop_remainder = False)\n",
    "test_dataset = test_dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9111a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def conv_block(inputs, n_filters, k_size, stride,layer_num, pad = \"same\",max_pool = False):\n",
    "    X = Conv2D(n_filters, k_size, stride, activation = \"relu\",padding = pad,name = 'conv'+str(layer_num))(inputs)\n",
    "    X = BatchNormalization(axis=-1,name = 'batch_norm'+str(layer_num))(X)\n",
    "    if max_pool:\n",
    "        X = MaxPooling2D(pool_size=(4, 4),padding = \"same\",name='max_pool'+str(layer_num))(X)\n",
    "    \n",
    "    return X\n",
    "    \n",
    "\n",
    "input_img = tf.keras.Input(shape = image_shape + (1,),name='input_image')\n",
    "conv1 = conv_block(input_img,16,5,1,1)\n",
    "conv2 = conv_block(conv1,16,5,1,2)\n",
    "conv3 = conv_block(conv2,16,5,2,3)\n",
    "conv4 = conv_block(conv3,32,5,1,4)\n",
    "conv5 = conv_block(conv4,32,5,1,5)\n",
    "conv6 = conv_block(conv5,32,5,2,6)\n",
    "conv7 = conv_block(conv6,64,5,1,7)\n",
    "conv8 = conv_block(conv7,64,5,1,8)\n",
    "conv9 = conv_block(conv8,64,5,2,9)\n",
    "conv10 = conv_block(conv9,128,5,1,10)\n",
    "conv11 = conv_block(conv10,128,5,1,11)\n",
    "conv12 = conv_block(conv11,128,5,2,12)\n",
    "conv13 = conv_block(conv12,256,5,1,13)\n",
    "conv14 = conv_block(conv13,256,5,1,14)\n",
    "conv15 = conv_block(conv14,256,5,2,15)\n",
    "conv16 = conv_block(conv15,512,5,1,16)\n",
    "conv17 = conv_block(conv16,512,5,1,17)\n",
    "conv18 = conv_block(conv17,512,5,2,18)\n",
    "\n",
    "\n",
    "flat19 = Flatten(name='flat19')(conv18)\n",
    "\n",
    "fc20 = Dense(1000,activation = \"relu\",name='fc20')(flat19)\n",
    "drop20 = Dropout(0.5,name='Dropout20')(fc20)\n",
    "merge20 = concatenate([drop20,flat19],name='merge20')\n",
    "fc21 = Dense(256,\n",
    "            activation = \"relu\",\n",
    "            kernel_regularizer=regularizers.L2(1e-4),\n",
    "            bias_regularizer=regularizers.L2(1e-4),\n",
    "            activity_regularizer=regularizers.L2(1e-5),name='fc21')(merge20)\n",
    "\n",
    "drop21 = Dropout(0.5,name='Dropout21')(fc21)\n",
    "merge21 = concatenate([drop21,merge20],name='merge21')\n",
    "fc22 = Dense(12,activation = None,name='fc22')(merge21)\n",
    "\n",
    "coefficient_network = tf.keras.Model(inputs = input_img, outputs = fc22, name=\"coefficient_network\")\n",
    "plot_model(coefficient_network, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6397f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def generate_orders(start,final):\n",
    "    N = []\n",
    "    M = []\n",
    "    for i  in range(start,final+1):\n",
    "        N.append(i * np.ones((i+1,)))\n",
    "        M.append(np.arange(-i,i+1,2))\n",
    "        \n",
    "    return (np.concatenate(N),np.concatenate(M))\n",
    "        \n",
    "\n",
    "def myzernike(n,m,r,theta):\n",
    "    Z = np.zeros((len(r),len(n)))\n",
    "    for i in range(0,len(n)):\n",
    "        for s in range(0,int((n[i] - abs(m[i]))/2)+1):\n",
    "            Z[:,i] = Z[:,i] + (-1)**s * math.factorial(int(n[i] - s)) / (math.factorial(int(s)) * math.factorial(int((n[i] + m[i])/2 - s)) * math.factorial(int((n[i]-m[i])/2 - s))) * r**(n[i] - 2*s)\n",
    "        \n",
    "        if m[i] < 0:\n",
    "            Z[:,i] = -Z[:,i] * np.sin(theta * m[i])\n",
    "        else:\n",
    "            Z[:,i] = Z[:,i] * np.cos(theta * m[i])\n",
    "    \n",
    "    return Z\n",
    "\n",
    "resolution = 200\n",
    "X = np.linspace(-1,1,resolution)\n",
    "[x,y] = np.meshgrid(X,X)\n",
    "[r,theta] = cart2pol(x,y)\n",
    "pupil = (r<=1)\n",
    "r = r * pupil\n",
    "theta = theta * pupil \n",
    "#theta = np.transpose(theta) # if you want Z matrix to be same as on MATLAB this should be transposed again later\n",
    "# python just has it in a different order to MATLAB\n",
    "r = r[np.nonzero(r)]\n",
    "theta = theta[np.nonzero(theta)]\n",
    "\n",
    "N,M = generate_orders(2,9)\n",
    "Z = myzernike(N,M,r,theta) # matrix of zernike polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c820d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FarField: # function for making far-field images\n",
    "    def __init__(self,wavelength):\n",
    "        self.radian_inator = 1e-6 * 2 * np.pi/(636e-9)\n",
    "        self.aperture_size = 0.2\n",
    "        self.noise_dev = 0.05\n",
    "        self.noise_mean = 0.05\n",
    "        \n",
    "    def generate_farfield(self,pupil_func):\n",
    "        row_col = np.array(np.shape(pupil_func)[1:]) # array of number of rows and columns\n",
    "        sz2 = row_col / self.aperture_size\n",
    "        padwidth = (np.round(sz2 -row_col)/2).astype(int)\n",
    "        paddings = tf.constant([[0,0],[padwidth[0],padwidth[0]],[padwidth[1],padwidth[1]]])\n",
    "        padded_pupil_func = tf.pad(pupil_func, paddings)\n",
    "        image = tf.signal.fftshift(tf.signal.fft2d(padded_pupil_func))\n",
    "        image = image[:,padwidth[0]:-padwidth[0],padwidth[1]:-padwidth[1]]\n",
    "        image = image * tf.math.conj(image)\n",
    "        #image = tf.math.sqrt(image)\n",
    "        image = tf.cast(image,tf.float32)\n",
    "        return image\n",
    "    \n",
    "FF = FarField(636e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8232ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generate_shape(layers.Layer): # custom layer to generate wavefront shapes from zernike coefficients\n",
    "    \n",
    "    def __init__(self,Z,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.Z = Z\n",
    "        \n",
    "    def call(self, zernike_coeffs,indices):\n",
    "        batch_size = tf.shape(zernike_coeffs)[0]\n",
    "        num_polynomials = np.minimum(np.shape(zernike_coeffs)[1],np.shape(self.Z)[1])\n",
    "        \n",
    "        self.Z = (self.Z)[:,0:num_polynomials]\n",
    "        zernike_coeffs = zernike_coeffs[:,0:num_polynomials]\n",
    "\n",
    "        \n",
    "        shape = tf.matmul(zernike_coeffs, tf.transpose(tf.cast(self.Z,tf.float32))) * FF.radian_inator\n",
    "\n",
    "        blank_wavefront = tf.zeros((1,200,200))\n",
    "        \n",
    "\n",
    "        tensor = tf.zeros((batch_size,200,200))\n",
    "        if np.shape(shape)[-1] == 1:\n",
    "            shape = tf.squeeze(shape,-1)\n",
    "        updates = shape\n",
    "        \n",
    "        i = tf.constant(0)\n",
    "\n",
    "        cond = lambda tensor, indices, updates, batch_size, i, blank_wavefront: tf.less(i,batch_size)    \n",
    "        \n",
    "        def body(tensor,indices,updates,batch_size,i,blank_wavefront):\n",
    "            #updates = lambda: updates\n",
    "            current_wavefront = tf.tensor_scatter_nd_update(tensor=tensor[i,:,:], indices=indices, updates = updates[i,:])\n",
    "            current_wavefront = tf.expand_dims(current_wavefront,axis=0)\n",
    "            i = tf.add(i, 1)\n",
    "            blank_wavefront = tf.concat([blank_wavefront,current_wavefront],axis=0)\n",
    "            return tensor, indices, updates, batch_size, i, blank_wavefront\n",
    "        \n",
    "        tensor, indices, updates, batch_size, i, blank_wavefront = tf.while_loop(cond,body,[tensor, indices, updates, batch_size, i, blank_wavefront],[tensor.get_shape(),indices.get_shape(),updates.get_shape(),batch_size.get_shape(),i.get_shape(),tf.TensorShape([None,resolution,resolution])])\n",
    "\n",
    "        wavefronts = blank_wavefront[1:,:,:] # I realise this is kinda messy but it works\n",
    "\n",
    "        return wavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6021c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generate_image(layers.Layer): # layer for combining shapes and outputting far-field\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        \n",
    "    def call(self,generated_shape,real_shape):\n",
    "        reverse_shape = -tf.reverse(generated_shape,[1,2]) # network may have found the reverse shape\n",
    "        shape1 = tf.subtract(real_shape,generated_shape) # find resultant shapes\n",
    "        shape2 = tf.subtract(real_shape,reverse_shape)\n",
    "        m1 = tf.reduce_mean(tf.square(shape1),[-2,-1])\n",
    "        m2 = tf.reduce_mean(tf.square(shape2),[-2,-1])\n",
    "        lower = tf.cast((m1<=m2),tf.float32)\n",
    "        lower = tf.expand_dims(tf.expand_dims(lower,-1),-1) # add dimensions so it can be broadcasted\n",
    "        shape1_lower = tf.multiply(shape1,lower) # sets examples of shape 1 with higher mean to 0\n",
    "        shape2_lower = tf.multiply(shape2,1-lower) # sets examples of shape 2 with higher mean to 0\n",
    "        better_shape = tf.add(shape1_lower,shape2_lower) # add the shapes to combine the best ones\n",
    "        pupil_func = pupil*tf.math.exp(tf.dtypes.complex(0.,better_shape))\n",
    "        gen_farfield = FF.generate_farfield(pupil_func) # find new farfield\n",
    "        \n",
    "        return [gen_farfield,better_shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72be160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class measure_quality(layers.Layer): # final layer for image quality\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self,generated_image):\n",
    "        maxI = tf.reduce_max(generated_image,[1,2])\n",
    "        normalised = tf.divide(generated_image,maxI[:,None,None])\n",
    "        quality = tf.reduce_sum(normalised,[1,2])\n",
    "        \n",
    "        return quality\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5390852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z = myzernike(N,M,r,theta)\n",
    "real_image = layers.Input(name=\"real_image_input\",shape = image_shape+(1,)) # inputs\n",
    "real_coeffs = layers.Input(name=\"real_coeffs_input\",shape = (36,))\n",
    "zernike_coeffs = coefficient_network(real_image) # predict coefficients\n",
    "indices = tf.where(pupil)\n",
    "generated_shape = generate_shape(Z,name='generated_shape')(zernike_coeffs,indices) # predicted wavefront shape\n",
    "real_shape = generate_shape(Z,name='real_shape')(real_coeffs,indices)\n",
    "[generated_image,corrected] = generate_image(name='generated_image')(generated_shape,real_shape) # resultant farfield\n",
    "image_quality = measure_quality(name='image_quality')(generated_image) # evaluate image quality\n",
    "qualityNet = Model(inputs = [real_image,real_coeffs],outputs=[image_quality,zernike_coeffs,generated_image,generated_shape,real_shape,corrected],name=\"qualityNet_untrained\")\n",
    "qualityNet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityModel(Model):\n",
    "\n",
    "    def __init__(self, qualityNet):\n",
    "        super().__init__()\n",
    "        self.qualityNet = qualityNet\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.qualityNet(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.qualityNet.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.qualityNet.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "        # update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # the loss is the generated image quality\n",
    "        loss = self.qualityNet(data)[0]\n",
    "        return loss \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61676e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(qualityNet,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_model = QualityModel(qualityNet)\n",
    "quality_model.compile(optimizer=optimizers.Adam(0.0001),weighted_metrics = [quality_model.metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f676d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualityNet.load_weights('q_model_nonrooted.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb196b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = quality_model.fit(train_dataset,epochs = 4,validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fd199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strehl_ratio(farfield):\n",
    "    maxI = np.max(farfield/np.sum(farfield))\n",
    "    I_0 = 0.03134885\n",
    "    sr = maxI/I_0\n",
    "    return(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036d4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "in1 = X_test[321]\n",
    "in2 = Y_test[321]\n",
    "in1 = tf.expand_dims(in1,0)\n",
    "in2 = tf.expand_dims(in2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(in1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = qualityNet.predict([in1,in2]) # if predicting multiple examples at once the output order is very strange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fdb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctedff = outputs[2]\n",
    "gen_shape = outputs[3]\n",
    "real_shape = outputs[4]\n",
    "corrected_shape = outputs[5]\n",
    "mse_real = mean_squared_error(real_shape[0],np.zeros((200,200)))\n",
    "mse_corr = mean_squared_error(corrected_shape[0],np.zeros((200,200)))\n",
    "sr_real = strehl_ratio(in1[0])\n",
    "sr_corr = strehl_ratio(correctedff[0])\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "rows=2\n",
    "columns=2\n",
    "fig.add_subplot(rows,columns,1)\n",
    "inff = plt.imshow(in1[0]/tf.reduce_max(in1[0]))\n",
    "fig.colorbar(inff)\n",
    "plt.axis('off')\n",
    "plt.title('Input far-field, Strehl ratio: %.4f' % sr_real)\n",
    "\n",
    "fig.add_subplot(rows,columns,2)\n",
    "cff = plt.imshow(correctedff[0]/np.max(correctedff[0]))\n",
    "fig.colorbar(cff)\n",
    "plt.axis('off')\n",
    "plt.title('Corrected far-field, Strehl ratio: %.4f' % sr_corr)\n",
    "\n",
    "fig.add_subplot(rows,columns,3)\n",
    "insh = plt.imshow(real_shape[0])\n",
    "fig.colorbar(insh)\n",
    "plt.axis('off')\n",
    "plt.title('Input shape, MSE: %0.4f' % mse_real)\n",
    "\n",
    "fig.add_subplot(rows,columns,4)\n",
    "gensh = plt.imshow(corrected_shape[0])\n",
    "fig.colorbar(gensh)\n",
    "plt.axis('off')\n",
    "plt.title('Corrected shape, MSE: %0.4f' % mse_corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54fe50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
