{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import cmath\n",
    "import scipy\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, concatenate\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import imageio.v3 as iio\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851709bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 200\n",
    "image_shape = (resolution, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = \"enter dataset location\"\n",
    "images = os.listdir(data_loc + \"/Train/Images\")\n",
    "labels = os.listdir(data_loc + \"/Train/Labels\")\n",
    "\n",
    "X_train_orig = list()\n",
    "Y_train_orig = list()\n",
    "n_train_images = np.shape(images)[0]\n",
    "\n",
    "for i in tqdm(range(np.shape(images)[0])):\n",
    "    X_train_orig.append(iio.imread(data_loc + \"/Train/Images/\" + images[i]))\n",
    "    Y_train_orig.append(pd.read_csv(data_loc + \"/Train/Labels/\" + labels[i], header = None))\n",
    "    \n",
    "X_train = np.reshape(X_train_orig,[n_train_images, resolution, resolution, 1]).astype(np.float32)\n",
    "Y_train = np.reshape(Y_train_orig,[n_train_images, 12, 1]).astype(np.float32)\n",
    "\n",
    "image_augmenter = ImageDataGenerator(rotation_range=4,width_shift_range=5.,height_shift_range=5.,zoom_range=[0.93,1.07])\n",
    "X_train = image_augmenter.flow(X_train,shuffle=False,batch_size=n_train_images)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4344b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(data_loc + \"/Test/Images\")\n",
    "labels = os.listdir(data_loc + \"/Test/Labels\")\n",
    "\n",
    "X_test_orig = list()\n",
    "Y_test_orig = list()\n",
    "n_test_images = np.shape(images)[0]\n",
    "\n",
    "for i in tqdm(range(np.shape(images)[0])):\n",
    "    X_test_orig.append(iio.imread(data_loc + \"/Test/Images/\" + images[i]))\n",
    "    Y_test_orig.append(pd.read_csv(data_loc + \"/Test/Labels/\" + labels[i], header = None))\n",
    "    \n",
    "X_test = np.reshape(X_test_orig,[n_test_images, resolution, resolution, 1]).astype(np.float32)\n",
    "Y_test = np.reshape(Y_test_orig,[n_test_images, 12, 1]).astype(np.float32)\n",
    "\n",
    "X_test = image_augmenter.flow(X_test,shuffle=False,batch_size=n_test_images)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2628ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "train_dataset = train_dataset.batch(64, drop_remainder = False)\n",
    "train_dataset = train_dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf369b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "test_dataset = test_dataset.batch(64, drop_remainder = False)\n",
    "test_dataset = test_dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ffb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, n_filters, k_size, stride, pad = \"same\",max_pool = False):\n",
    "    X = Conv2D(n_filters, k_size, stride, activation = \"relu\",padding = pad)(inputs)\n",
    "    X = BatchNormalization(axis=-1)(X)\n",
    "    if max_pool:\n",
    "        X = MaxPooling2D(pool_size=(4, 4),padding = \"same\")(X)\n",
    "    \n",
    "    return X\n",
    "    \n",
    "\n",
    "input_img = tf.keras.Input(shape = image_shape + (1,))\n",
    "conv1 = conv_block(input_img,16,5,1)\n",
    "conv2 = conv_block(conv1,16,5,1)\n",
    "conv3 = conv_block(conv2,16,5,2)\n",
    "conv4 = conv_block(conv3,32,5,1)\n",
    "conv5 = conv_block(conv4,32,5,1)\n",
    "conv6 = conv_block(conv5,32,5,2)\n",
    "conv7 = conv_block(conv6,64,5,1)\n",
    "conv8 = conv_block(conv7,64,5,1)\n",
    "conv9 = conv_block(conv8,64,5,2)\n",
    "conv10 = conv_block(conv9,128,5,1)\n",
    "conv11 = conv_block(conv10,128,5,1)\n",
    "conv12 = conv_block(conv11,128,5,2)\n",
    "conv13 = conv_block(conv12,256,5,1)\n",
    "conv14 = conv_block(conv13,256,5,1)\n",
    "conv15 = conv_block(conv14,256,5,2)\n",
    "conv16 = conv_block(conv15,512,5,1)\n",
    "conv17 = conv_block(conv16,512,5,1)\n",
    "conv18 = conv_block(conv17,512,5,2)\n",
    "\n",
    "\n",
    "flat5 = Flatten()(conv18)\n",
    "\n",
    "fc6 = Dense(1000,activation = \"relu\")(flat5)\n",
    "drop6 = Dropout(0.5)(fc6)\n",
    "merge6 = concatenate([drop6,flat5])\n",
    "fc7 = Dense(256,activation = \"relu\")(merge6)\n",
    "drop7 = Dropout(0.5)(fc7)\n",
    "merge7 = concatenate([drop7,merge6])\n",
    "fc8 = Dense(128,activation = None)(merge7)\n",
    "\n",
    "embedding = tf.keras.Model(inputs = input_img, outputs = fc8, name=\"Embedding\")\n",
    "embedding.load_weights(\"encoder.h5\")\n",
    "embedding.trainable = False\n",
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8658e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def generate_orders(start,final):\n",
    "    N = []\n",
    "    M = []\n",
    "    for i  in range(start,final+1):\n",
    "        N.append(i * np.ones((i+1,)))\n",
    "        M.append(np.arange(-i,i+1,2))\n",
    "        \n",
    "    return (np.concatenate(N),np.concatenate(M))\n",
    "        \n",
    "\n",
    "def myzernike(n,m,r,theta):\n",
    "    Z = np.zeros((len(r),len(n)))\n",
    "    for i in range(0,len(n)):\n",
    "        for s in range(0,int((n[i] - abs(m[i]))/2)+1):\n",
    "            Z[:,i] = Z[:,i] + (-1)**s * math.factorial(int(n[i] - s)) / (math.factorial(int(s)) * math.factorial(int((n[i] + m[i])/2 - s)) * math.factorial(int((n[i]-m[i])/2 - s))) * r**(n[i] - 2*s)\n",
    "        \n",
    "        if m[i] < 0:\n",
    "            Z[:,i] = -Z[:,i] * np.sin(theta * m[i])\n",
    "        else:\n",
    "            Z[:,i] = Z[:,i] * np.cos(theta * m[i])\n",
    "    \n",
    "    return Z\n",
    "\n",
    "resolution = 200\n",
    "X = np.linspace(-1,1,resolution)\n",
    "[x,y] = np.meshgrid(X,X)\n",
    "[r,theta] = cart2pol(x,y)\n",
    "pupil = (r<=1)\n",
    "r = r * pupil\n",
    "theta = theta * pupil \n",
    "#theta = np.transpose(theta) # if you want Z matrix to be same as on MATLAB this should be transposed again later\n",
    "# python just has it in a different order to MATLAB\n",
    "r = r[np.nonzero(r)]\n",
    "theta = theta[np.nonzero(theta)]\n",
    "print(np.shape(r))\n",
    "print(np.shape(theta))\n",
    "\n",
    "N,M = generate_orders(2,9)\n",
    "Z = myzernike(N,M,r,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff386aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FarField:\n",
    "    def __init__(self,wavelength):\n",
    "        self.radian_inator = 1e-6 * 2 * np.pi/(636e-9)\n",
    "        self.aperture_size = 0.2\n",
    "        self.noise_dev = 0.05\n",
    "        self.noise_mean = 0.05\n",
    "        \n",
    "    def generate_farfield(self,pupil_func):\n",
    "        row_col = np.array(np.shape(pupil_func)[1:]) # array of number of rows and columns\n",
    "        sz2 = row_col / self.aperture_size\n",
    "        padwidth = (np.round(sz2 -row_col)/2).astype(int)\n",
    "        paddings = tf.constant([[0,0],[padwidth[0],padwidth[0]],[padwidth[1],padwidth[1]]])\n",
    "        padded_pupil_func = tf.pad(pupil_func, paddings)\n",
    "        image = tf.signal.fftshift(tf.signal.fft2d(padded_pupil_func))\n",
    "        image = image[:,padwidth[0]:-padwidth[0],padwidth[1]:-padwidth[1]]\n",
    "        image = image * tf.math.conj(image)\n",
    "        image = tf.math.sqrt(image)\n",
    "        image = tf.cast(image,tf.float32)\n",
    "        return image\n",
    "    \n",
    "FF = FarField(636e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0377155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generate_image(layers.Layer):\n",
    "    \n",
    "    def __init__(self,Z,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.Z = Z\n",
    "        \n",
    "    def call(self, zernike_coeffs,indices):\n",
    "        batch_size = tf.shape(zernike_coeffs)[0]\n",
    "        num_polynomials = np.minimum(np.shape(zernike_coeffs)[1],np.shape(self.Z)[1])\n",
    "        \n",
    "        self.Z = (self.Z)[:,0:num_polynomials]\n",
    "        zernike_coeffs = zernike_coeffs[:,0:num_polynomials]\n",
    "       # zernike_coeffs = tf.expand_dims(zernike_coeffs,-1)\n",
    "      #  self.Z = tf.convert_to_tensor(self.Z)\n",
    "      #  self.Z = tf.expand_dims(self.Z,axis = 0)\n",
    "      #  self.Z = tf.repeat(self.Z,batch_size,axis = 0)\n",
    "        \n",
    "        shape = tf.matmul(zernike_coeffs, tf.transpose(tf.cast(self.Z,tf.float32))) * FF.radian_inator\n",
    "\n",
    "       # indices = tf.where(pupil_tensor)\n",
    "        #indices = tf.expand_dims(indices,0)\n",
    "\n",
    "       # indices = tf.repeat(indices,batch_size,axis = 0)\n",
    "        \n",
    "        blank_wavefront = tf.zeros((1,200,200))\n",
    "        \n",
    "\n",
    "        tensor = tf.zeros((batch_size,200,200))\n",
    "        updates = tf.squeeze(shape)\n",
    "        \n",
    "        i = tf.constant(0)\n",
    "\n",
    "        cond = lambda tensor, indices, updates, batch_size, i, blank_wavefront: tf.less(i,batch_size)    \n",
    "        \n",
    "        def body(tensor,indices,updates,batch_size,i,blank_wavefront):\n",
    "            current_wavefront = tf.tensor_scatter_nd_update(tensor=tensor[i,:,:], indices=indices, updates = updates[i,:])\n",
    "            current_wavefront = tf.expand_dims(current_wavefront,axis=0)\n",
    "            i = tf.add(i, 1)\n",
    "            blank_wavefront = tf.concat([blank_wavefront,current_wavefront],axis=0)\n",
    "            return tensor, indices, updates, batch_size, i, blank_wavefront\n",
    "        \n",
    "        tensor, indices, updates, batch_size, i, blank_wavefront = tf.while_loop(cond,body,[tensor, indices, updates, batch_size, i, blank_wavefront],[tensor.get_shape(),indices.get_shape(),updates.get_shape(),batch_size.get_shape(),i.get_shape(),tf.TensorShape([None,resolution,resolution])])\n",
    "\n",
    "        blank_wavefront = blank_wavefront[1:,:,:] # I realise this is very messy\n",
    "        wavefront = blank_wavefront\n",
    "        pupil_func = tf.math.exp(tf.dtypes.complex(0.,wavefront))\n",
    "        gen_farfield = FF.generate_farfield(pupil_func)\n",
    "        #gen_farfield = tf.expand_dims(gen_farfield,-1)\n",
    "        return gen_farfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cosine_similarity(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, real_embedding, generated_embedding):\n",
    "        dot = tf.math.reduce_sum(tf.multiply(real_embedding,generated_embedding),axis = -1)\n",
    "        norms = tf.math.multiply(tf.norm(real_embedding), tf.norm(generated_embedding))\n",
    "        similarity = (tf.divide(dot,norms))\n",
    "        return (similarity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6dd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = myzernike(N,M,r,theta)\n",
    "real_image = layers.Input(name=\"real_image_input\",shape = image_shape+(1,))\n",
    "zernike_coeffs = coefficient_network(real_image)\n",
    "#attempt = tf.expand_dims(pupil,0)\n",
    "#attempt = tf.repeat(attempt,12,axis = 0)\n",
    "indexes = tf.where(pupil)\n",
    "print(indexes)\n",
    "generated_image = generate_image(Z)(zernike_coeffs,indexes)\n",
    "similarity = cosine_similarity()(embedding(real_image),embedding(generated_image))\n",
    "\n",
    "full_network = Model(inputs = real_image,outputs = similarity,name = \"full_network\")\n",
    "full_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e20f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(full_network,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbcb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(Model):\n",
    "    def __init__(self, full_network):\n",
    "        super().__init__()\n",
    "        self.full_network = full_network\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.full_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.full_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.full_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        similarity = self.full_network(data[0])\n",
    "\n",
    "        loss = 1 - similarity\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = FullModel(full_network)\n",
    "full_model.compile(optimizer=optimizers.Adam(0.0001),weighted_metrics = [full_model.metrics])\n",
    "full_model.fit(train_dataset,epochs = 5,validation_data=test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
